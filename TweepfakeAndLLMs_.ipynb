{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkr2VcbS04rKPFOMCAlKkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreel143/tweepfake_deepfake_text_detection/blob/master/TweepfakeAndLLMs_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Mounting Drive and Accessing the dataset"
      ],
      "metadata": {
        "id": "WTqt2HzAHu6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsO5cpXEJzg-",
        "outputId": "4776e919-be7b-4835-d896-13887fd437da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrJlJBUiHrSJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/BTP/Dataset\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj_JS6uRKIxq",
        "outputId": "e3d65459-93c1-4c7c-e0d7-7d6bb3ed48f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RawDataset.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel(\"/content/drive/MyDrive/BTP/Dataset/RawDataset.xlsx\")"
      ],
      "metadata": {
        "id": "sxvYPSIkK3-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DATASET INFO:\")\n",
        "print(df)\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjEnzQiULL5H",
        "outputId": "648226bb-a47b-411f-ccd4-7ba64a43aefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET INFO:\n",
            "          screen_name                                               text  \\\n",
            "0          imranyebot                             YEA now that note GOOD   \n",
            "1              zawvrk  Listen to This Charming Man by The Smiths  htt...   \n",
            "2            zawarbot  wish i can i would be seeing other hoes on the...   \n",
            "3      ahadsheriffbot  The decade in the significantly easier schedul...   \n",
            "4       kevinhookebot  \"Theim class=\\\"alignnone size-full wp-image-60...   \n",
            "...               ...                                                ...   \n",
            "25567      DeepDrumpf  You're going to be even prouder when we don't ...   \n",
            "25568           jaden    https://t.co/10XkzXDBCf https://t.co/cIUIYWEB45   \n",
            "25569     ahadsheriff  2. “Once you take the place of the people who ...   \n",
            "25570      imranyebot  black will be like a company with them need so...   \n",
            "25571   GenePark_GPT2  Guys, I hate Facebook. And this Facebook ad ca...   \n",
            "\n",
            "      account.type class_type  \n",
            "0              bot     others  \n",
            "1            human      human  \n",
            "2              bot     others  \n",
            "3              bot     others  \n",
            "4              bot        rnn  \n",
            "...            ...        ...  \n",
            "25567          bot        rnn  \n",
            "25568        human      human  \n",
            "25569        human      human  \n",
            "25570          bot     others  \n",
            "25571          bot       gpt2  \n",
            "\n",
            "[25572 rows x 4 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25572 entries, 0 to 25571\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   screen_name   25572 non-null  object\n",
            " 1   text          25572 non-null  object\n",
            " 2   account.type  25572 non-null  object\n",
            " 3   class_type    25572 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 799.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in concatenated dataset\n",
        "print(\"\\nMissing Values: \")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLM-RjzsLTSr",
        "outputId": "c01e9931-a3b8-4de9-df28-c08be7a232a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values: \n",
            "screen_name     0\n",
            "text            0\n",
            "account.type    0\n",
            "class_type      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nh4Y0LOLV9S",
        "outputId": "4e95085e-c1cd-4aab-ba14-d64776315f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 25572 entries, 0 to 25571\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   screen_name   25572 non-null  object\n",
            " 1   text          25572 non-null  object\n",
            " 2   account.type  25572 non-null  object\n",
            " 3   class_type    25572 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 998.9+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DATASET INFO:\")\n",
        "print(df)\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19FnzfVkLs3Q",
        "outputId": "aca461a9-93c5-4c92-a098-673ae73047d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET INFO:\n",
            "          screen_name                                               text  \\\n",
            "0          imranyebot                             YEA now that note GOOD   \n",
            "1              zawvrk  Listen to This Charming Man by The Smiths  htt...   \n",
            "2            zawarbot  wish i can i would be seeing other hoes on the...   \n",
            "3      ahadsheriffbot  The decade in the significantly easier schedul...   \n",
            "4       kevinhookebot  \"Theim class=\\\"alignnone size-full wp-image-60...   \n",
            "...               ...                                                ...   \n",
            "25567      DeepDrumpf  You're going to be even prouder when we don't ...   \n",
            "25568           jaden    https://t.co/10XkzXDBCf https://t.co/cIUIYWEB45   \n",
            "25569     ahadsheriff  2. “Once you take the place of the people who ...   \n",
            "25570      imranyebot  black will be like a company with them need so...   \n",
            "25571   GenePark_GPT2  Guys, I hate Facebook. And this Facebook ad ca...   \n",
            "\n",
            "      account.type class_type  \n",
            "0              bot     others  \n",
            "1            human      human  \n",
            "2              bot     others  \n",
            "3              bot     others  \n",
            "4              bot        rnn  \n",
            "...            ...        ...  \n",
            "25567          bot        rnn  \n",
            "25568        human      human  \n",
            "25569        human      human  \n",
            "25570          bot     others  \n",
            "25571          bot       gpt2  \n",
            "\n",
            "[25572 rows x 4 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 25572 entries, 0 to 25571\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   screen_name   25572 non-null  object\n",
            " 1   text          25572 non-null  object\n",
            " 2   account.type  25572 non-null  object\n",
            " 3   class_type    25572 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 998.9+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Encoding the dataset"
      ],
      "metadata": {
        "id": "PCS9EeM1IEQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying unique values in the 'account.type' column\n",
        "unique_values = df['account.type'].unique()\n",
        "print(unique_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN0yPY6zMFgB",
        "outputId": "7683ea8d-ab76-4d97-abdb-6eb5c1fd2b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bot' 'human']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a mapping dictionary that covers all variations found in the unique values\n",
        "label_mapping = {\n",
        "    'human': 0,\n",
        "    'bot': 1,\n",
        "}"
      ],
      "metadata": {
        "id": "bcfSxgL5MKOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the mapping to the 'account.type' column\n",
        "df['account.type'] = df['account.type'].map(label_mapping)"
      ],
      "metadata": {
        "id": "LuwuBCgCMO1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ENCODED DATASET INFO:\")\n",
        "print(df.info())\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNn0gjn5Mbxg",
        "outputId": "9259426e-d75e-4084-9d3f-552260a6349b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENCODED DATASET INFO:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 25572 entries, 0 to 25571\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   screen_name   25572 non-null  object\n",
            " 1   text          25572 non-null  object\n",
            " 2   account.type  25572 non-null  int64 \n",
            " 3   class_type    25572 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 998.9+ KB\n",
            "None\n",
            "          screen_name                                               text  \\\n",
            "0          imranyebot                             YEA now that note GOOD   \n",
            "1              zawvrk  Listen to This Charming Man by The Smiths  htt...   \n",
            "2            zawarbot  wish i can i would be seeing other hoes on the...   \n",
            "3      ahadsheriffbot  The decade in the significantly easier schedul...   \n",
            "4       kevinhookebot  \"Theim class=\\\"alignnone size-full wp-image-60...   \n",
            "...               ...                                                ...   \n",
            "25567      DeepDrumpf  You're going to be even prouder when we don't ...   \n",
            "25568           jaden    https://t.co/10XkzXDBCf https://t.co/cIUIYWEB45   \n",
            "25569     ahadsheriff  2. “Once you take the place of the people who ...   \n",
            "25570      imranyebot  black will be like a company with them need so...   \n",
            "25571   GenePark_GPT2  Guys, I hate Facebook. And this Facebook ad ca...   \n",
            "\n",
            "       account.type class_type  \n",
            "0                 1     others  \n",
            "1                 0      human  \n",
            "2                 1     others  \n",
            "3                 1     others  \n",
            "4                 1        rnn  \n",
            "...             ...        ...  \n",
            "25567             1        rnn  \n",
            "25568             0      human  \n",
            "25569             0      human  \n",
            "25570             1     others  \n",
            "25571             1       gpt2  \n",
            "\n",
            "[25572 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(\"/content/drive/MyDrive/BTP/Dataset/EncodedDataset.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "KyRUVNT9MnTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Utilising LLMs"
      ],
      "metadata": {
        "id": "mrKvzOLwILL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the encoded dataset"
      ],
      "metadata": {
        "id": "BXVw0UGNUaUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_excel(\"/content/drive/MyDrive/BTP/Dataset/EncodedDataset.xlsx\")"
      ],
      "metadata": {
        "id": "hOCR8EiYJCRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a sample df to test the LLM"
      ],
      "metadata": {
        "id": "8uk1keC8OyiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for AI-generated texts\n",
        "ai_texts = df1[df1['account.type'] == 0].sample(n=10)\n",
        "\n",
        "# Filter for human-generated texts\n",
        "human_texts = df1[df1['account.type'] == 1].sample(n=10)\n",
        "\n",
        "# Combine the filtered subsets\n",
        "sample_df1 = pd.concat([ai_texts, human_texts]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "u_2PYCmLOZAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SAMPLE DATASET INFO:\")\n",
        "print(sample_df1.info())\n",
        "print(sample_df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuP8M_xVPYlY",
        "outputId": "f75bc0c3-e7aa-4719-d6c9-0cb6487a8543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE DATASET INFO:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20 entries, 0 to 19\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   screen_name   20 non-null     object\n",
            " 1   text          20 non-null     object\n",
            " 2   account.type  20 non-null     int64 \n",
            " 3   class_type    20 non-null     object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 768.0+ bytes\n",
            "None\n",
            "        screen_name                                               text  \\\n",
            "0            zawvrk  im not built for the heat can winter come back...   \n",
            "1   realDonaldTrump  ...Won all against the Federal Government and ...   \n",
            "2        kevinhooke  @W3ARDstroke5 @k4wpx @TxRadioGeek @MWimages @a...   \n",
            "3       ahadsheriff        Everyone loves rice https://t.co/RubgrNuV7a   \n",
            "4        kevinhooke  This is perfect <U+0001F604> https://t.co/pVom...   \n",
            "5              dril                @Ulillillysses no!! this is fucked!   \n",
            "6       ahadsheriff  I’m only on TikTok for the cats and Indian com...   \n",
            "7        kevinhooke  Click. Screenshot. Share. https://t.co/o5HB8in8VJ   \n",
            "8        kevinhooke  This looks like a portable version of the Icom...   \n",
            "9        kevinhooke                @QuinnyPig That's an eyebrow raiser   \n",
            "10    kevinhookebot  \"Theile&lt;/service.java/0/201706/img_5a7dd40d...   \n",
            "11        dril_gpt2  you wanna tell me Im bad again?? ok ur up agai...   \n",
            "12  theJadenTrudeau                  great to Listen To celebrate Them   \n",
            "13  theJadenTrudeau     our Support our first night at Vimy and I Only   \n",
            "14    kevinhookebot  \"The for each submittes with the what the open...   \n",
            "15  theJadenTrudeau                                 Forever Even Ready   \n",
            "16       whalefakes  i haven’t made the cut, but i'm always in the ...   \n",
            "17  theJadenTrudeau  My Best Moment of Visibility, and friends And ...   \n",
            "18    GenePark_GPT2  CNN goes viral by saying their EDITOR is terrible   \n",
            "19       botustrump  The infighting at the top wether the new firin...   \n",
            "\n",
            "    account.type class_type  \n",
            "0              0      human  \n",
            "1              0      human  \n",
            "2              0      human  \n",
            "3              0      human  \n",
            "4              0      human  \n",
            "5              0      human  \n",
            "6              0      human  \n",
            "7              0      human  \n",
            "8              0      human  \n",
            "9              0      human  \n",
            "10             1        rnn  \n",
            "11             1       gpt2  \n",
            "12             1     others  \n",
            "13             1     others  \n",
            "14             1        rnn  \n",
            "15             1     others  \n",
            "16             1       gpt2  \n",
            "17             1     others  \n",
            "18             1       gpt2  \n",
            "19             1       gpt2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the LLM and making function"
      ],
      "metadata": {
        "id": "C1e4SJ9UTodA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1viUSIIqN1Dl",
        "outputId": "5827a0a8-0c4f-4584-efdb-e95675155e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/76.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "Kbry_9cYN9q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your OpenAI API key\n",
        "openai.api_key = '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'"
      ],
      "metadata": {
        "id": "aijQimYLOAlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM specific function to predict whether text is from a human or bot\n",
        "def predict_human_or_bot(text):\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"gpt-3.5-turbo\",\n",
        "      prompt=f\"Is the following tweet written by a human or a bot?\\n\\nTweet: \\\"{text}\\\"\\n\\nPrediction:\",\n",
        "      temperature=0,\n",
        "      max_tokens=1\n",
        "    )\n",
        "    prediction = response.choices[0].text.strip()\n",
        "    return 0 if prediction.lower() == \"human\" else 1"
      ],
      "metadata": {
        "id": "EeUVHi4eOD9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calling the function via the dataset file, saving the results"
      ],
      "metadata": {
        "id": "oXf9WGJ8IY0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions and store them in a new column\n",
        "sample_df1['LLM1_predicted_acType'] = sample_df1['text'].apply(predict_human_or_bot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "sk8C7dOtOMgk",
        "outputId": "3134863a-4200-4af3-8015-d26a1498c6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidRequestError",
          "evalue": "This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-64eb0fe6e8bb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make predictions and store them in a new column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_df1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_acType'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_df1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_human_or_bot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-dcb938d1d377>\u001b[0m in \u001b[0;36mpredict_human_or_bot\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# LLM specific function to predict whether text is from a human or bot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_human_or_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Is the following tweet written by a human or a bot?\\n\\nTweet: \\\"{text}\\\"\\n\\nPrediction:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the model works properly for the small subset then we move to entire dataset"
      ],
      "metadata": {
        "id": "GYHdTmzwQLGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions and store them in a new column named predicted_acType\n",
        "df1['LLM1_predicted_acType'] = df1['text'].apply(predict_human_or_bot)"
      ],
      "metadata": {
        "id": "4EIFIPEoQT8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DATASET INFO:\")\n",
        "print(df1.info())\n",
        "print(df1)"
      ],
      "metadata": {
        "id": "pSSHgxFcSuOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating the efficiency of the model"
      ],
      "metadata": {
        "id": "c5N0F3NLJXyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLM1_accuracy = (df1['account.type'] == df['LLM1_predicted_acType']).mean()\n",
        "\n",
        "print(f'Accuracy of LLM1 : {LLM1_accuracy:.2%}')"
      ],
      "metadata": {
        "id": "g61mI8xYSlsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding the result to excel file"
      ],
      "metadata": {
        "id": "S-OwwN8UTUjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_excel(\"/content/drive/MyDrive/BTP/Dataset/Output.xlsx\")"
      ],
      "metadata": {
        "id": "M2YzNg-rREZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving to next model"
      ],
      "metadata": {
        "id": "IN02BOfoJhki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a. Loading the dataset"
      ],
      "metadata": {
        "id": "0y5vUuWjU_bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2=pd.read_excel(\"/content/drive/MyDrive/BTP/Dataset/Output.xlsx\")"
      ],
      "metadata": {
        "id": "SNseMBjZUrB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Creating a sample df to test the LLM"
      ],
      "metadata": {
        "id": "iw94XWMeVfim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for AI-generated texts\n",
        "ai_texts = df2[df2['account.type'] == 0].sample(n=10)\n",
        "\n",
        "# Filter for human-generated texts\n",
        "human_texts = df2[df2['account.type'] == 1].sample(n=10)\n",
        "\n",
        "# Combine the filtered subsets\n",
        "sample_df2 = pd.concat([ai_texts, human_texts]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ySZxs4omVPao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SAMPLE DATASET INFO:\")\n",
        "print(sample_df2.info())\n",
        "print(sample_df2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3ckRccjVnKU",
        "outputId": "14fc1f35-f8f1-4980-c387-b5221d010b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE DATASET INFO:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20 entries, 0 to 19\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   screen_name   20 non-null     object\n",
            " 1   text          20 non-null     object\n",
            " 2   account.type  20 non-null     int64 \n",
            " 3   class_type    20 non-null     object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 768.0+ bytes\n",
            "None\n",
            "        screen_name                                               text  \\\n",
            "0        kevinhooke  If you were upset that Microsoft bought GitHub...   \n",
            "1           imranye  for those who prefer this as a facebook messen...   \n",
            "2      narendramodi  Very happy to learn of the successful start to...   \n",
            "3        kevinhooke  One of the highest voted Java questions on Sta...   \n",
            "4          GenePark  all the ____4Pete accounts trying to prove the...   \n",
            "5            Thorin  @GODaZeD You could make a case Shaq would scor...   \n",
            "6              dril  slamming some coins into the juke box and play...   \n",
            "7   realDonaldTrump  “This is no longer about peaceful protesting, ...   \n",
            "8      narendramodi  Launching the PM Garib Kalyan Rojgar Yojana to...   \n",
            "9              dril  my followers love to Drool &amp; Shit like a b...   \n",
            "10  theJadenTrudeau  Hope at Pride events of the Greatest Dancer of...   \n",
            "11   ahadsheriffbot                               See That’s all night   \n",
            "12   AINarendraModi       Best wishes of the people of the #MannKiBaat   \n",
            "13       imranyebot       I’ve got a lot when ya imam now <U+0001F621>   \n",
            "14         zawarbot  Interstellar Old grandma greek ladies this the...   \n",
            "15  theJadenTrudeau                                  Come To Canadians   \n",
            "16        dril_gpt2  merry christmas, time to get the gang together...   \n",
            "17    kevinhookebot  \"The Eclipse Open\\r\\n\\r\\nJava and running http...   \n",
            "18    GenePark_GPT2  Guys, I hate Facebook. And this Facebook ad ca...   \n",
            "19        dril_gpt2  at first i thought thunder storms were the wor...   \n",
            "\n",
            "    account.type class_type  \n",
            "0              0      human  \n",
            "1              0      human  \n",
            "2              0      human  \n",
            "3              0      human  \n",
            "4              0      human  \n",
            "5              0      human  \n",
            "6              0      human  \n",
            "7              0      human  \n",
            "8              0      human  \n",
            "9              0      human  \n",
            "10             1     others  \n",
            "11             1     others  \n",
            "12             1        rnn  \n",
            "13             1     others  \n",
            "14             1     others  \n",
            "15             1     others  \n",
            "16             1       gpt2  \n",
            "17             1        rnn  \n",
            "18             1       gpt2  \n",
            "19             1       gpt2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. Setting up the LLM and making function"
      ],
      "metadata": {
        "id": "_MEJx65AVj3C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uEdoBpqbXopL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d. Calling the function via the dataset file, saving the results"
      ],
      "metadata": {
        "id": "DzT4TNb1W24t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions and store them in a new column\n",
        "sample_df2['LLM2_predicted_acType'] = sample_df2['text'].apply(predict_human_or_bot)"
      ],
      "metadata": {
        "id": "QO_zW35_W-_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the model works properly for the small subset then we move to entire dataset"
      ],
      "metadata": {
        "id": "3tY-s9mqXXXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2['LLM2_predicted_acType'] = df2['text'].apply(predict_human_or_bot)"
      ],
      "metadata": {
        "id": "iFOBZGRDXcJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### e. Calculating the efficiency of the model"
      ],
      "metadata": {
        "id": "H_4ZUhBYXmxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLM2_accuracy = (df1['account.type'] == df['LLM2_predicted_acType']).mean()\n",
        "\n",
        "print(f'Accuracy of LLM2 : {LLM2_accuracy:.2%}')"
      ],
      "metadata": {
        "id": "7pWBDDfkXwb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing Various LLMs\n"
      ],
      "metadata": {
        "id": "MdfrEZktYykf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Model': ['LLM1_name1', 'LLM2_name2'],\n",
        "    'Accuracy': [LLM1_accuracy, LLM2_accuracy],\n",
        "}\n",
        "\n",
        "accuracy_df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "5hmZCY7rY4OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_df_sorted = accuracy_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "5ntDNItkZDxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "D7HBwGB7a3Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Barplot"
      ],
      "metadata": {
        "id": "4fdfivr_ab53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the visualization style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.barplot(x='Accuracy', y='Model', data=accuracy_df_sorted, palette='coolwarm')\n",
        "\n",
        "# Add the accuracy values on the bars\n",
        "for p in ax.patches:\n",
        "    width = p.get_width()\n",
        "    plt.text(5+p.get_width(), p.get_y()+0.55*p.get_height(),\n",
        "             '{:1.2f}'.format(width),\n",
        "             ha='center', va='center')\n",
        "\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Model')\n",
        "plt.xlim(0, 1)  # Assuming accuracy is between 0 and 1\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BsJPVClOZIH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using HeatMap"
      ],
      "metadata": {
        "id": "EQ_6HpSyasr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap_data = pd.pivot_table(accuracy_df_sorted, values='Accuracy', index=['Model'], columns=[])\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", cmap='coolwarm', cbar_kws={'label': 'Accuracy'})\n",
        "plt.title('Heatmap of Model Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9OLS0Nq_ZZSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}